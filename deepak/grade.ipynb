{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e819000-f406-4d7c-a58b-68555dd0f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ffe50c8-2d33-4cc4-9cec-396feb5c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from houghLines import HoughLines, show_lines, slope_close_to, merge_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffae0f6-6684-4752-af55-944cc025e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349cd518-b169-4202-ac3c-16d0d8854fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_Y_RATIO = 600/2200\n",
    "BINARY_THRESHOLD = 200\n",
    "\n",
    "HOUGH_RHO_RES = 1/4\n",
    "HOUGH_THETA_RES = np.pi/(4*180)\n",
    "HOUGH_THRESHOLD = 300\n",
    "VERTICAL_SLOPE_TOL = 15\n",
    "RHO_MERGE_TOL = 10/1700\n",
    "\n",
    "BOX_HEIGHT = 25 # needs to be a ratio (25/2200)\n",
    "YGAP_BETWEEN_BOXES = 18 # needs to be a ratio (18/2200)\n",
    "WRITTEN_AVG_INTENSITY_THRESH = 4\n",
    "\n",
    "MIN_AVG_INTENSITY_SHADED_BOX = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e1d82a-680c-44d3-8a5d-9c1f07c60b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, vertical_edges=False):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    blurred_cropped = blurred[int(ROI_Y_RATIO*gray.shape[0]):, :]\n",
    "    (T, threshinv) = cv2.threshold(blurred_cropped, BINARY_THRESHOLD, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    if vertical_edges:\n",
    "        sobel_kernel = np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T\n",
    "        pf = cv2.filter2D(src=threshinv, ddepth=-1, kernel=sobel_kernel)\n",
    "        return pf\n",
    "    return threshinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe80717e-1929-4f9f-975b-bfbc98d3b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_lines(img):\n",
    "    lines, acc_grid, thetas, rhos = HoughLines(img, HOUGH_RHO_RES, HOUGH_THETA_RES, HOUGH_THRESHOLD)\n",
    "    sorted_lines = lines[np.argsort(lines[:, 0])]\n",
    "    vertical_lines = sorted_lines[slope_close_to(sorted_lines[:, 1], 0, tol=VERTICAL_SLOPE_TOL)]\n",
    "    vertical_lines_merged = vertical_lines[merge_lines(vertical_lines, min_gap=int(RHO_MERGE_TOL*img.shape[1]))]\n",
    "    return vertical_lines_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c426b7-c32c-4a67-9ec9-78744a748107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches(img, vertical_lines, stack, sub_stack, col=None):\n",
    "    y1,y2 = 0,img.shape[0]\n",
    "    \n",
    "    if sub_stack == 0:\n",
    "        x1= 0 if stack==0 else int(vertical_lines[12*stack-1,0])\n",
    "        x2=int(vertical_lines[12*stack,0])\n",
    "    elif sub_stack == 1:\n",
    "        x1=int(vertical_lines[12*stack,0])\n",
    "        x2=int(vertical_lines[12*stack+2,0])\n",
    "    else:\n",
    "        if col is None:\n",
    "            x1=int(vertical_lines[12*stack+2,0])\n",
    "            x2=int(vertical_lines[12*stack+11,0])\n",
    "        else:\n",
    "            x1=int(vertical_lines[12*stack+2+2*col,0])\n",
    "            x2=int(vertical_lines[12*stack+2+2*col+1,0])\n",
    "    \n",
    "    # print(x1,x2,y1,y2)\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def connected_components(data):\n",
    "    labels = np.zeros_like(data).astype(np.uint64)\n",
    "    n = 0\n",
    "    for i in range(len(data[1:])):\n",
    "        left = data[i-1]\n",
    "        if data[i] != 0:\n",
    "            if left == 0:\n",
    "                n += 1\n",
    "                labels[i] = n\n",
    "            else:\n",
    "                labels[i] = n\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def segment(p, min_width, min_intensity):\n",
    "    data = np.sum(p, axis=1)/p.shape[1]\n",
    "    data_thresh = data.copy()\n",
    "    data_thresh[data_thresh < 20] = 0\n",
    "    cc = connected_components(data_thresh)\n",
    "\n",
    "    # remove components with width less than min_width\n",
    "    labels = set(np.unique(cc))-{0}\n",
    "    for c in labels:\n",
    "        if cc[cc == c].shape[0] < min_width:\n",
    "            cc[cc == c] = 0\n",
    "\n",
    "    labels = set(np.unique(cc))-{0}\n",
    "\n",
    "    # calculate average intensity of each component\n",
    "    avg_intensity = np.zeros(len(labels))\n",
    "    for i, c in enumerate(labels):\n",
    "        avg_intensity[i] = np.mean(data_thresh[cc == c])\n",
    "\n",
    "    # map components with intensity less than min_intensity as 0 (unfilled) otherwise 1 (filled)\n",
    "    return [1 if i > min_intensity else 0 for i in avg_intensity], cc, avg_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27714672-b2c0-45fc-8523-9615088a420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(img, vertical_lines):\n",
    "    answers = defaultdict(list)\n",
    "    for stack in [0, 1, 2]: # iterating over 3 stacks\n",
    "        for col in [0, 1, 2, 3, 4]: # iterating over A, B, C, D, E columns\n",
    "            p = patches(img, vertical_lines, stack=stack, sub_stack=2, col=col)\n",
    "            qnum_start = 29*stack\n",
    "            filled, cc, _ = segment(p, min_width=BOX_HEIGHT, min_intensity=MIN_AVG_INTENSITY_SHADED_BOX)  # TODO\n",
    "            print(stack, col, len(filled))\n",
    "            for i, f in enumerate(filled):\n",
    "                if f == 1: # if the box is shaded, f is 1, 0 otherwise\n",
    "                    q_num = qnum_start + i + 1\n",
    "                    answers[q_num].append(col)\n",
    "    return answers\n",
    "\n",
    "def get_written(img, vertical_lines):\n",
    "    written = {}\n",
    "    for stack in [0,1,2]:\n",
    "        p = patches(img, vertical_lines, stack=stack, sub_stack=0)\n",
    "        qnum_start = 29*stack\n",
    "        options_col_p = patches(img, vertical_lines, stack=stack, sub_stack=2, col=0)\n",
    "        filled, cc, _ = segment(options_col_p, min_width=BOX_HEIGHT, min_intensity=180)\n",
    "\n",
    "        for i,c in enumerate(set(np.unique(cc))-{0}):\n",
    "            s=np.nonzero(cc==c)[0] #indexes (y) of pixels from start to end of the box (in vertical direction)\n",
    "            \n",
    "            # extend the y boundaries to include half the gap between the boxes, both up and down\n",
    "            margin = int(Y_GAP_BETWEEN_BOXES/2)\n",
    "            y1, y2 = s[0]-margin, s[-1]+margin\n",
    "            \n",
    "            # reduce the boundaries horizontally to exclude box boudaries that sometimes leak into this patch.\n",
    "            x1, x2 = 5, -5\n",
    "            \n",
    "            avg_intensity = np.mean(p[y1:y2, x1:x2])\n",
    "            q_num = qnum_start + i + 1\n",
    "            written[q_num] = avg_intensity > WRITTEN_AVG_INTENSITY_THRESH\n",
    "    return written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1cb545-152f-4218-92f5-95db86398530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_str(qnum, answers, written):\n",
    "    return f'{qnum} {\"\".join([chr(ord(\"A\")+a) for a in answers])}{\" x\" if written[qnum] else \"\"}'\n",
    "\n",
    "def write_to_file(answers, written, output_fname=None):\n",
    "    answers_str = [answer_str(i, anss, written) for i, anss in sorted(answers.items())]\n",
    "    \n",
    "    if output_fname:\n",
    "        with open(output_fname, 'w') as f:\n",
    "            f.write('\\n'.join(answers_str))\n",
    "    return answers_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3492afa-2aeb-42f6-81cd-61046b9736a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_answers(groundtruth_file, answers_strs):\n",
    "    with open('../test-images/a-30_groundtruth.txt') as f:\n",
    "        groundturth = f.read().split('\\n')\n",
    "    return groundturth == answers_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eb965-22f0-4cd7-ad88-49acb4ba77be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b2a2b-4b29-42ef-a6f0-8d2fac3bd103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7158a74c-c0fc-487d-b2a9-f507db2afa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag 2335.0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../test-images/blank_form.jpg')\n",
    "img_processed = preprocess(img)\n",
    "vlines = get_vertical_lines(img_processed)\n",
    "if vlines.shape[0] != 36:\n",
    "    raise Exception(f'found {vlines.shape[0]} vertical lines, expecting 36.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4289c965-2228-4317-b3cf-764d91ae65e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-433789ae47e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8b7084ba465f>\u001b[0m in \u001b[0;36mget_answers\u001b[0;34m(img, vertical_lines)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mqnum_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mfilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBOX_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_intensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_AVG_INTENSITY_SHADED_BOX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "answers = get_answers(img_processed, vlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaec5659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-74ac40e5b491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBOX_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_intensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_AVG_INTENSITY_SHADED_BOX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "filled, cc = segment(p, min_width=BOX_HEIGHT, min_intensity=MIN_AVG_INTENSITY_SHADED_BOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09527cc2-44cc-46c5-ab8a-5b9b3bde7ea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-69b6fa9189c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwritten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_written\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8b7084ba465f>\u001b[0m in \u001b[0;36mget_written\u001b[0;34m(img, vertical_lines)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mqnum_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptions_col_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_col_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBOX_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_intensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "written = get_written(img_processed, vlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902beea-a9bc-4b44-a848-bafbe2a9e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_strs = write_to_file(answers, written, 'a-30_results2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10323a09-df75-45f1-b5bf-8055caf76892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c08d4b-320e-4671-ada4-338e485d05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = patches(img_processed, vlines, stack=2, sub_stack=2, col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24ec04-243f-403c-a836-be01928c2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=27\n",
    "plt.figure(figsize=(n_clusters,6))\n",
    "data = np.sum(p, axis=1)/p.shape[1]\n",
    "data_thresh = data.copy()\n",
    "data_thresh[data_thresh<20] = 0\n",
    "plt.plot(np.arange(len(data_thresh)), data_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62db36b-39e3-4f13-a394-e02f058af957",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled, cc, avg_int = segment(p, min_width=BOX_HEIGHT, min_intensity=160)\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73763364-459f-469c-b94b-752fbe682355",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6a2c2-e1e6-4478-98db-6e9d559d0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(cc)\n",
    "color_map = {l:np.random.choice(range(256), size=3).astype(np.float64)/255 for l in unique_labels} #assign random color to each label\n",
    "color_map[0] = np.array([0, 0, 0])/255\n",
    "\n",
    "plt.figure(figsize=(n_clusters,6))\n",
    "# plt.plot(np.arange(len(data_thresh)), data_thresh, color='black')\n",
    "for c in np.unique(cc):\n",
    "    plt.plot(np.where(cc==c)[0], data_thresh[cc==c], color=color_map[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c4b76-879e-4b1f-a61d-d92491631351",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(np.unique(cc))-{0}\n",
    "\n",
    "# calculate average intensity of each component\n",
    "avg_intensity = np.zeros(len(labels))\n",
    "for i, c in enumerate(labels):\n",
    "    avg_intensity[i] = np.mean(data_thresh[cc == c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80060d-3471-417c-afc2-33560f65e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee7a83-5a3e-44a3-9f7e-ad8ae0388770",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(avg_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6717d5-8a6b-4c4f-9e3c-ab4da5e6bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108ce5d-dfbe-47ab-8ce7-eac42f1da40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(avg_intensity.reshape(-1,1))\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8200965-7f62-4625-827a-e3d4c7cb7756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be3b78-bffa-4af8-b329-2af8d2ddc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5bfed-1586-42ab-8d8a-2b0d6fbfc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = patches(img_processed, vlines, stack=2, sub_stack=2, col=3)\n",
    "p_dilation = ndimage.binary_dilation(p)\n",
    "p_closing = ndimage.binary_closing(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7d51c-0727-4e8f-9ecb-14a2c1bfcd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_new = p#255*p_closing.astype(np.uint8)\n",
    "filled, cc = segment(p_new, min_width=BOX_HEIGHT, min_intensity=180)\n",
    "labels = set(np.unique(cc))-{0}\n",
    "\n",
    "data = np.sum(p_new, axis=1)/p.shape[1]\n",
    "data_thresh = data.copy()\n",
    "data_thresh[data_thresh<20] = 0\n",
    "\n",
    "# calculate average intensity of each component\n",
    "avg_intensity = np.zeros(len(labels))\n",
    "for i, c in enumerate(labels):\n",
    "    avg_intensity[i] = np.mean(data_thresh[cc == c])\n",
    "    \n",
    "plt.hist(avg_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075ad98-f098-4230-9a6a-f95a21a2d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(p_closing, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8c120-9de0-41a8-8156-ac2716f8bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_lines(img_processed, vlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b94ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
